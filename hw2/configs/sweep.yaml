output_dir: outputs/sweep  # <- where the output files are written
method: all
num_run: 0                    # Not relevant if method is all
tokenizer_encoding: gpt2      # <- the tokenizer encoding, used by tiktoken (YOU SHOULD NOT CHANGE THIS)
save_model: True
device: auto                  # <- which device to put the model on (YOU DO NOT NEED TO CHANGE THIS)
tag: final-sweep
name_prefix: final-sweep
parameters:
  n_embd: [64]                # <- dimension of token and positional embeddings 
  n_head: [8]                 # <- number of attention heads in multihead attention
  seq_len: [64]           # <- the maximum number of tokens that the model can take
  n_layer: [2]                # <- number of decoder blocks
  batch_size: [32]                # <- number of sequences to feed into the model at a time
  num_warmup_steps: [10]          # <- number of warmup steps in cosine annealing
  num_training_steps: [2000]      # <- number of training steps in cosine annealing
  max_flops: [1e-15]
  lr: [(1e-5, 5e-5), (5e-6, 2.5e-5), (2e-6, 1e-5), (2e-5, 1e-4), (4e-5, 2e-4)]
